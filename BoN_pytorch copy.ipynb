{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from torchvision.models import vgg16,VGG16_Weights, resnet101,ResNet101_Weights\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Config Values ###\n",
    "\n",
    "IMG_SHAPE = (224,224,3)\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40\n",
    "SHUFFLE = True\n",
    "SEED = 42\n",
    "CLASSES =['cats'] # for OC-CNN\n",
    "CLASSES_T =['unknown','cat','dog'] # for BoN-CNN\n",
    "CLASSES_B =['wild','cat','dog'] # for Bon test\n",
    "TRAIN_PATH = r\"C:\\Users\\asiclab06\\Datasets\\afhq\\train\"\n",
    "TEST_PATH = r\"C:\\Users\\asiclab06\\Datasets\\afhq\\val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Dataset\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,root,classes,target_size:tuple,shuffle=False,**kwargs):\n",
    "        super().__init__()\n",
    "        self.root=  root\n",
    "        self.classes = classes\n",
    "        self.target_size = target_size\n",
    "        self.shuffle = shuffle        \n",
    "\n",
    "        self._load_data()\n",
    "        self._set_index_array()     \n",
    "        self._set_shuffle()\n",
    "    \n",
    "        # kwargs\n",
    "        self.samples = kwargs.pop('samples',None)\n",
    "        if self.samples is not None:\n",
    "            self._sampling_data()\n",
    "\n",
    "    def _sampling_data(self):\n",
    "        s = np.random.choice(self.__len__()-self.samples,1).item() if self.shuffle else 0\n",
    "        e = self.samples\n",
    "        self.data = self.data[s:e+s]\n",
    "        self.label = self.label[s:e+s]\n",
    "\n",
    "    def _load_data(self):\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "        for i,cla in enumerate(self.classes):\n",
    "            sub_dir = os.path.join(self.root,cla)\n",
    "            if not os.path.exists(sub_dir):\n",
    "                print(f'Not found images in \"{cla}\" directory.')\n",
    "                continue\n",
    "            sub_files = os.listdir(sub_dir)\n",
    "            self.data.extend([os.path.join(sub_dir,sub_file) for sub_file in sub_files])\n",
    "            l=len(sub_files)\n",
    "            self.label.extend([i for _ in range(l)])\n",
    "            print(f'Found {l} images in \"{cla}\" directory.')\n",
    "\n",
    "        self.data = np.array(self.data) \n",
    "        self.label = np.array(self.label)\n",
    "        \n",
    "    def _set_index_array(self):\n",
    "        self.index_array = np.arange(self.__len__())\n",
    "        if self.shuffle:\n",
    "            self.index_array = np.random.permutation(self.__len__())\n",
    "\n",
    "    def _set_shuffle(self):\n",
    "        self.data = self.data[self.index_array]\n",
    "        self.label = self.label[self.index_array]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "            Return : PIL image, sparse label\n",
    "        \"\"\"\n",
    "        x = Image.open(self.data[index]).convert('RGB')\n",
    "        x = x.resize(self.target_size[:2],Image.Resampling.BILINEAR)\n",
    "        \n",
    "\n",
    "        return x, self.label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class FaceClfDataset(ImageDataset):\n",
    "    def __init__(self, root, classes, target_size: tuple, shuffle=False, transform=None, class_mode=None, **kwargs):\n",
    "        super().__init__(root, classes, target_size, shuffle, **kwargs)\n",
    "        # transform\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "        self.allow_class_modes =  [\"categorical\",\"sparse\",None]\n",
    "\n",
    "        if class_mode is not None:\n",
    "            self.class_mode = class_mode\n",
    "        else:\n",
    "            self.class_mode = self.allow_class_modes[0]\n",
    "\n",
    "    def _class_mode(self,y):\n",
    "        if self.class_mode == self.allow_class_modes[0]:\n",
    "            return self._to_categorical_class(y)\n",
    "        elif self.class_mode == self.allow_class_modes[1]:\n",
    "            return torch.tensor(y,dtype=torch.long)\n",
    "\n",
    "    def _to_categorical_class(self,y):\n",
    "        temp = torch.zeros((len(self.classes),),dtype=torch.long)\n",
    "        temp[y] = 1\n",
    "        return temp \n",
    "\n",
    "    def categorical2sparse(y:torch.Tensor):\n",
    "        return torch.argmax(y,1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x,y = super().__getitem__(index)\n",
    "        return self.transform(x),self._class_mode(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return super().__len__()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found images in \"unknown\" directory.\n",
      "Found 5153 images in \"cat\" directory.\n",
      "Found 4739 images in \"dog\" directory.\n",
      "Found 500 images in \"wild\" directory.\n",
      "Found 500 images in \"cat\" directory.\n",
      "Found 500 images in \"dog\" directory.\n"
     ]
    }
   ],
   "source": [
    "## train, val set\n",
    "train_dataset = FaceClfDataset(TRAIN_PATH,CLASSES_T,(IMG_SHAPE),SHUFFLE,class_mode='categorical')\n",
    "train_loader = DataLoader(train_dataset,BATCH_SIZE,SHUFFLE)\n",
    "\n",
    "test_dataset = FaceClfDataset(TEST_PATH,CLASSES_B,(IMG_SHAPE),False,class_mode='categorical')\n",
    "test_loader = DataLoader(test_dataset,BATCH_SIZE,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utills \n",
    "\n",
    "def wrap_generator(generator):\n",
    "    while True:\n",
    "        x,y = next(iter(generator))\n",
    "        zeros = torch.zeros_like(y) + torch.Tensor([1.,0.,0.]) # add fake label\n",
    "        y = torch.concat([y,zeros], axis=0)\n",
    "        yield x,y\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues,cm_proba=True):\n",
    "    if cm_proba:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=25)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n",
    "    plt.yticks(tick_marks, classes, fontsize=15)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 14)\n",
    "\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n",
    "\n",
    "def plot_confusion_matrix_detail(cm,classes):\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(121)\n",
    "    plot_confusion_matrix(cm,classes)\n",
    "    plt.subplot(122)\n",
    "    plot_confusion_matrix(cm,classes,cm_proba=False)\n",
    "    \n",
    "def sample_from_derectory(base_path=TEST_PATH,labels=CLASSES_T): # func only this file\n",
    "    f, axes = plt.subplots(2, 3, sharex=True, sharey=True, figsize = (16,7))\n",
    "    samples = []\n",
    "    for ax in axes.ravel():\n",
    "        label = np.random.choice(os.listdir(base_path))\n",
    "        i = np.where(np.array(labels)==label)[0]\n",
    "        img = np.random.choice(os.listdir(base_path + label))\n",
    "        img = Image.open(base_path + label + \"/\" + img) # os.path.join\n",
    "        img = img.resize(IMG_SHAPE[:2],resample=Image.Resampling.NEAREST)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(label+\" \"+str(i))  \n",
    "        samples.append(np.array(img))\n",
    "    \n",
    "    return np.array(samples)\n",
    "\n",
    "def plot_result(samples,preds,true_label=None,labels=CLASSES_B):\n",
    "    f, axes = plt.subplots(2, 3, sharex=True, sharey=True, figsize = (16,7))\n",
    "    \n",
    "    for i,ax in enumerate(axes.ravel()):\n",
    "        label = labels[preds[i]]\n",
    "        l = preds[i]\n",
    "        img = Image.fromarray(samples[i])\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(\"P : \"+label+\" \"+str(l))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "## models \n",
    "\n",
    "def get_vgg16(n_classes,device = torch.device('cuda:0')):\n",
    "    vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "    for param in vgg.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # clf.add_module(str(clf.__len__()),\n",
    "    #     nn.Linear(in_features=4096, out_features=n_classes, bias=True))\n",
    "    clf = nn.Linear(in_features=4096, out_features=n_classes, bias=True)\n",
    "\n",
    "    return nn.Sequential(vgg.features,nn.Flatten(),vgg.classifier[:1]).to(device),clf.to(device)\n",
    "\n",
    "def get_resnet101(n_classes,device = torch.device('cuda:0')):\n",
    "    resnet = resnet101(weights=ResNet101_Weights.IMAGENET1K_V1)\n",
    "    for param in resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    clf = nn.Linear(in_features=2048, out_features=n_classes, bias=True)\n",
    "    return nn.Sequential(*[_ for _ in resnet.children()][:-1],nn.Flatten()).to(device),clf.to(device)\n",
    "\n",
    "class OCCNN(nn.Module):\n",
    "    def __init__(self,n_classes,backbone:str,device):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            n_classes : trainning classes number. ex. ['cat','dog'] => n_classes = 2\n",
    "            backbone : current allow model [vgg16, resnet101] \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.n_classes = n_classes\n",
    "        self.backbone, self.clf = self._get_backbone(backbone)\n",
    "\n",
    "        self.inm = nn.InstanceNorm1d(self.clf.in_features)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if self.device == torch.device('cuda:0'):\n",
    "            self.cuda()\n",
    "        else:\n",
    "            self.cpu()\n",
    "        \n",
    "        a = next(self.backbone.parameters()).device\n",
    "        print(f\"Model is on device: {a}\")\n",
    "    \n",
    "    def _get_backbone(self,b):\n",
    "        return eval(f'get_{b}(self.n_classes,\"{self.device}\")')\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        if self.training:\n",
    "            unk_vector = torch.normal(0.,0.01,x.shape,device=self.device)\n",
    "            x = self.inm(x)\n",
    "            x = torch.concat([x,unk_vector],0)\n",
    "            x = self.relu(x)\n",
    "        else :\n",
    "            x = x\n",
    "\n",
    "        x = self.clf(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def fit(self,\n",
    "        train_generator,\n",
    "        epochs,\n",
    "        lr,\n",
    "        device,\n",
    "        val_generator=None\n",
    "        ):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optim = torch.optim.Adam(self.parameters(),)\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            self.train()\n",
    "            for x,y in tqdm(train_generator):\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                pred = self.forward(x)\n",
    "\n",
    "                optim.zero_grad()\n",
    "                loss = criterion(pred,y)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "    \n",
    "    def predict(self,test_generator):\n",
    "        preds = torch.Tensor([],device=self.device)\n",
    "        for x,y in test_generator:\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            pred = self.forward(x)\n",
    "\n",
    "            preds = torch.concat(preds,pred)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "c = OCCNN(3,'resnet101',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1773it [15:03,  2.14it/s]"
     ]
    }
   ],
   "source": [
    "## BoN train\n",
    "c.fit(wrap_generator(train_loader),1,1e-3,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FaceClfDataset(TEST_PATH,CLASSES_B,(IMG_SHAPE),False,class_mode='categorical')\n",
    "test_loader = DataLoader(test_dataset,BATCH_SIZE,False,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:00<00:05,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:01<00:07,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:02<00:07,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:03<00:07,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:04<00:06,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:05<00:05,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:06<00:04,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [00:07<00:03,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:08<00:02,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [00:09<00:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [00:10<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:10<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i ,data in enumerate((tqdm(test_loader))):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c12c419fb877effd9e13c85f1b267b5ef22e851a6af2e6405c99ea71c0dd76c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
